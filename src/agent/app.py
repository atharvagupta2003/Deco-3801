from flask import Flask, request, jsonify
import os
import logging
from flask_cors import CORS
from src.agent.graph import setup_workflow
from src.agent.graph import workflow, graph

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'txt', 'csv', 'pdf'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16 MB max file size


@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy'}), 200


def run_graph_workflow(question: str):
    """
    This function runs the graph workflow with the given question and returns the generated AI answer.

    Args:
        question (str): The question to ask the graph.

    Returns:
        str: The AI-generated answer.
    """
    # Ensure graph is initialized
    if graph is None:
        logging.error("Graph is not initialized.")
        return "Error: Graph not initialized."

    inputs = {"question": question}

    # Configuration required by the checkpointer
    config = {
        "configurable": {
            "thread_id": "1",  # Example thread_id, adjust as needed
            "checkpoint_ns": "default_ns",
            "checkpoint_id": "checkpoint_1"
        }
    }

    output = None

    try:
        # Run the graph to process the question
        for event in graph.stream(inputs, stream_mode="values", config=config):
            output = event  # Capture the output

            # Extract the AI-generated answer from the 'generation' part
            if 'generation' in output:
                generation = output['generation']
                return generation.content  # Return the actual content generated by the AI
            else:
                logging.warning(f"Unexpected event structure: {output}")

        # Check if output is empty or invalid
        if not output:
            logging.error("No output received from the graph.")
            return "Error: No output received from the AI."

    except Exception as e:
        logging.error(f"Error during graph processing: {str(e)}")
        return f"Error during AI processing: {str(e)}"

    logging.error("No 'generation' found in the graph output.")
    return "Error: No generation found in the AI response."

@app.route('/ask', methods=['POST'])
def ask():
    try:
        data = request.json
        if 'question' not in data:
            return jsonify({'error': 'No question provided'}), 400

        question = data['question']
        logging.info(f"Received question: {question}")

        # Use the helper function to run the graph workflow and get the AI-generated answer
        answer = run_graph_workflow(question)

        if answer:
            # Return the AI-generated answer
            logging.info(f"Answer generated for question: {question}")
            return jsonify({'answer': answer}), 200
        else:
            return jsonify({'error': 'No answer generated by the AI.'}), 500
    except Exception as e:
        logging.error(f"Error in ask: {str(e)}")
        return jsonify({'error': f'Internal server error: {str(e)}'}), 500


if __name__ == '__main__':
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
    app.run(debug=True, host='0.0.0.0', port=5050)